# Ollama AI Configuration
# Make sure Ollama is running: ollama serve
# Then pull a model: ollama pull gemma3:270m
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=gemma3:270m

# Server Configuration
PORT=3000
NODE_ENV=development

# CORS Configuration
FRONTEND_URL=http://localhost:5173

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100
